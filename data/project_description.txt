## Challenge context
The Linky smart meter has been deployed for the vast majority of the 38 million low-voltage customers of Enedis, providing daily updates on electricity consumption data, as well as intraday consumption curves when the customer chooses this option.

Enedis uses some of these curves to provide estimates of consumption aggregates on an intraday basis as part of market mechanisms that ensure supply and demand balance at all times on the electricity network.

However, data collection, like every mass process, may undergo technical problems at every stage of the metering and collection chain, resulting in missing values. In order to fulfill its mission, Enedis must develop algorithms to fill in missing values of these electric load curves, but without using the real load curves.

In order to comply with the General Data Protection Regulation (GPRD), we developped a synthetic load curves generator, DeepCourboGen, which creates curves that look like real one but do not in any way allow for customer identification.

## Challenge goals
The challenge that we propose here is to rebuild missing data from synthetic electric load curves, using only the load of other synthetic consumers.

We used a synthetic electric load curve generation tool, DeepCourbogen, to generate around 69 000 synthetic load curves. 1 000 of these curves were subjected to random data removal, in order to simulate the missing data of real load curves.

The goal of that challenge is to propose replacements for missing values (“fill the holes”) in the 1 000 curves.

## Data description
For the train sample : 
- The input is a dataframe of 21 000 columns. Each of them is a synthetic load curve generated by DeepCourbogen. Each column name is a randomly generated identification token . The index is the timestamp of each point, the values are in watts. The 1 000 last columns contain curves with randomly generated missing values (these columns are labelled holed_).
- The output is a dataframe containing the completed data of the last 1 000 columns of the input.
- The input sample weights 140 MB, the output sample 6 MB

For the test sample, the input sample is a 38 140 columns dataframe (260 MB), the output sample is still a 1000 columns dataframe (6 MB)

## Benchmark description
### Benchmark :
For this challenge, we used a basic benchmark consisting of linear interpolation on missing data.
Broadly speaking, this method fills in the missing values with the values taken by the affine function passing through the previous known point and the next known point.
For more details, please refer to this article: https://en.wikipedia.org/wiki/Linear_interpolation

```
def fill_nan_with_interpolation(column):
    col = column.copy()
    col = col.interpolate(method='linear', limit_direction='both')
    return col
y_pred = X_test_holed.apply(fill_nan_with_interpolation, axis=0)
```

### Metric :
The metric used for the evaluation is a simple MAE (Mean Absolute Error), which is the average of the absolute errors reduced to the actual number of missing values.
